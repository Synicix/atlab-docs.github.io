

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>synicix_ml_pipeline.datajoint_tables.TrainingResult &mdash; atlab-docs 0.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../../../',
              VERSION:'0.0.0',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> atlab-docs
          

          
          </a>

          
            
            
              <div class="version">
                0.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../datajoint.html">DataJoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docker.html">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kubernetes.html">Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stimulus.html">Stimulus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../synicix_ml_pipeline_tutorial.html">Synicix ML Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../synicix_ml_pipeline_modules.html">Synicix ML Pipeline API Documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">atlab-docs</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>synicix_ml_pipeline.datajoint_tables.TrainingResult</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for synicix_ml_pipeline.datajoint_tables.TrainingResult</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">datajoint</span> <span class="k">as</span> <span class="nn">dj</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">synicix_ml_pipeline.datajoint_tables.BaseTable</span> <span class="kn">import</span> <span class="n">schema</span>
<span class="kn">from</span> <span class="nn">synicix_ml_pipeline.datajoint_tables.BaseTable</span> <span class="kn">import</span> <span class="n">BaseTable</span>
<span class="kn">from</span> <span class="nn">synicix_ml_pipeline.datajoint_tables.DatasetConfig</span> <span class="kn">import</span> <span class="n">DatasetConfig</span>
<span class="kn">from</span> <span class="nn">synicix_ml_pipeline.datajoint_tables.ModelConfig</span> <span class="kn">import</span> <span class="n">ModelConfig</span>
<span class="kn">from</span> <span class="nn">synicix_ml_pipeline.datajoint_tables.TrainingConfig</span> <span class="kn">import</span> <span class="n">TrainingConfig</span>
<span class="kn">from</span> <span class="nn">synicix_ml_pipeline.datajoint_tables.TrainingTask</span> <span class="kn">import</span> <span class="n">TrainingTask</span>

<div class="viewcode-block" id="TrainingResult"><a class="viewcode-back" href="../../../synicix_ml_pipeline.datajoint_tables.html#synicix_ml_pipeline.datajoint_tables.TrainingResult.TrainingResult">[docs]</a><span class="nd">@schema</span>
<span class="k">class</span> <span class="nc">TrainingResult</span><span class="p">(</span><span class="n">dj</span><span class="o">.</span><span class="n">Computed</span><span class="p">,</span> <span class="n">BaseTable</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A dj.Computed that handle the training of the networks based on the dataset, model, and training configs defined in TrainingTask</span>

<span class="sd">    Typical usage of this class is done via the K8/TrainingDeployment/training_script.py with K8 deploy script nameed training_deployment.yaml</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">definition</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        -&gt; TrainingTask</span>
<span class="s2">        ---</span>
<span class="s2">        test_score				                  : float</span>
<span class="s2">        training_epoch_loss_history               : blob@external_training_result</span>
<span class="s2">        validation_epoch_loss_history             : blob@external_training_result</span>
<span class="s2">        regularization_loss_history               : blob@external_training_result</span>
<span class="s2">        model_class_params_history                : blob@external_training_result</span>
<span class="s2">        model_save_path			                  : varchar(256)</span>
<span class="s2">        utc_insert_time = CURRENT_TIMESTAMP   : timestamp</span>
<span class="s2">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_dir</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">dataset_cache_dir</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>  <span class="n">model_save_dir</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize function for TrainingResult which is use to define dataset_dir, dataset_cache_dir,  model_save_dir, device, num_workers</span>

<span class="sd">        Parameters:</span>
<span class="sd">            dataset_dir (str): Directory of where the dataset file are located</span>
<span class="sd">            dataset_cache_dir (str): Directory of where to cache the dataset files</span>
<span class="sd">            model_save_dir (str): Directory of where to save and load the trained model weights</span>
<span class="sd">            device (str): Pytorch Device to loat the model on to. If not defined then it will use the 1st GPU if avaliable else CPU</span>
<span class="sd">            num_workers (int): Number of pytorch dataloading workers, default is 0</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_save_dir</span> <span class="o">=</span> <span class="n">model_save_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span> <span class="o">=</span> <span class="n">DatasetConfig</span><span class="p">(</span><span class="n">dataset_dir</span><span class="o">=</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">dataset_cache_dir</span><span class="o">=</span><span class="n">dataset_cache_dir</span><span class="p">)</span>

        <span class="c1"># If device was not define, use cuda:0 if avaliable, if not then use CPU</span>
        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>

<div class="viewcode-block" id="TrainingResult.make"><a class="viewcode-back" href="../../../synicix_ml_pipeline.datajoint_tables.html#synicix_ml_pipeline.datajoint_tables.TrainingResult.TrainingResult.make">[docs]</a>    <span class="k">def</span> <span class="nf">make</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called during population to handle training of the specific TrainingTask restricted by key and save the relavent information into the table</span>

<span class="sd">        Parameters:</span>
<span class="sd">            key (dict): Dict to restrict TrainingResult.key_source by which is TrainingTask</span>
<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the trainer</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_trainer</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>        

        <span class="c1"># Start the training process</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Extract the data that is needed to insert into TrainingResult</span>
        <span class="n">key</span><span class="p">[</span><span class="s1">&#39;model_save_path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model_save_path</span>
        <span class="n">key</span><span class="p">[</span><span class="s1">&#39;training_epoch_loss_history&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">training_epoch_loss_history</span>
        <span class="n">key</span><span class="p">[</span><span class="s1">&#39;validation_epoch_loss_history&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validation_epoch_loss_history</span>
        <span class="n">key</span><span class="p">[</span><span class="s1">&#39;regularization_loss_history&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">regularization_loss_history</span>
        <span class="n">key</span><span class="p">[</span><span class="s1">&#39;model_class_params_history&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model_class_params_history_dict</span>
        <span class="n">key</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test_score</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">insert1</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sucessfully Trained and Saved Results&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainingResult.get_test_set_outputs_targets_and_losses"><a class="viewcode-back" href="../../../synicix_ml_pipeline.datajoint_tables.html#synicix_ml_pipeline.datajoint_tables.TrainingResult.TrainingResult.get_test_set_outputs_targets_and_losses">[docs]</a>    <span class="k">def</span> <span class="nf">get_test_set_outputs_targets_and_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function that loads the trained model and returns all test_set outputs, targets, and loss</span>

<span class="sd">        Typically use for additional analysis</span>

<span class="sd">        Parameters:</span>
<span class="sd">            key (dict): Dict to restrict TrainingResult.key_source by which is TrainingTask</span>
<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing outputs, targets, and losses Tensors. keys = (outputs, targets, losses)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get Trainer</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_trainer</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="c1"># Load the best performing model and extract the outputs, target, and lossess</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">load_best_performing_model</span><span class="p">()</span>
        <span class="n">outputs_targets_and_losses</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">return_outputs_targets_and_losses</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Extract the outputs, targets, and losses into assembled_outputs_targets_and_losses_dict into a clean way, that is not split by batches</span>
        <span class="n">assembled_outputs_targets_and_losses_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">dict_key</span> <span class="ow">in</span> <span class="n">outputs_targets_and_losses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">outputs_targets_and_losses</span><span class="p">:</span>
                <span class="c1"># Add a list entry for the key if the key does not exist yet in the assembled_outputs_targets_and_losses_dict</span>
                <span class="k">if</span> <span class="n">dict_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                
                <span class="c1"># Append each array batch to their respective list</span>
                <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">dict_key</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>  

            <span class="c1"># Rearrange the list into one array</span>
            <span class="k">if</span> <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="n">dict_key</span><span class="p">])</span>

        <span class="c1"># Rename loss as losses</span>
        <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="p">[</span><span class="s1">&#39;losses&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">assembled_outputs_targets_and_losses_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">assembled_outputs_targets_and_losses_dict</span></div>
            
<div class="viewcode-block" id="TrainingResult.get_trainer"><a class="viewcode-back" href="../../../synicix_ml_pipeline.datajoint_tables.html#synicix_ml_pipeline.datajoint_tables.TrainingResult.TrainingResult.get_trainer">[docs]</a>    <span class="k">def</span> <span class="nf">get_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function that get the trainer based on the key and returns it</span>

<span class="sd">        Parameters:</span>
<span class="sd">            key (dict): Dict to restrict TrainingResult.key_source by which is TrainingTask</span>
<span class="sd">        Returns:</span>
<span class="sd">            &lt;user_defined_class&gt;: Returns the trainer given by the configuration defined by TrainingTask restrict by the given key</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Get that dataset_config primary key, input_shape and output_shape</span>
        <span class="n">dataset_config_key</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">additional_model_params</span> <span class="o">=</span> <span class="p">(</span><span class="n">DatasetConfig</span> <span class="o">*</span> <span class="n">TrainingTask</span> <span class="o">&amp;</span> <span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">fetch1</span><span class="p">(</span><span class="s1">&#39;KEY&#39;</span><span class="p">,</span> <span class="s1">&#39;input_shape&#39;</span><span class="p">,</span> <span class="s1">&#39;output_shape&#39;</span><span class="p">,</span> <span class="s1">&#39;additional_model_params&#39;</span><span class="p">)</span>
         
        <span class="c1"># Get the revelant fields from TrainingConfig</span>
        <span class="n">training_config_tuple_dict</span> <span class="o">=</span> <span class="p">((</span><span class="n">TrainingTask</span> <span class="o">&amp;</span> <span class="n">key</span><span class="p">)</span> <span class="o">*</span> <span class="n">TrainingConfig</span><span class="p">)</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;epoch_limit&#39;</span><span class="p">,</span> <span class="s1">&#39;trainer_class_module_name&#39;</span><span class="p">,</span> <span class="s1">&#39;trainer_class_name&#39;</span><span class="p">,</span> <span class="s1">&#39;trainer_class_params&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fetch1</span><span class="p">()</span>

        <span class="c1"># Get the train_dataloader, validation_datalaoder, test_dataloader</span>
        <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validation_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">get_dataloaders</span><span class="p">(</span><span class="n">dataset_config_key</span><span class="p">,</span> <span class="n">training_config_tuple_dict</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)</span>
    
        <span class="c1"># Get the model, optimizer, and criterion using the helper functions</span>
        <span class="n">model_class</span><span class="p">,</span> <span class="n">model_class_params</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="o">.</span><span class="n">get_model_class_and_params</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">optimizer_class</span><span class="p">,</span> <span class="n">optimizer_class_params</span> <span class="o">=</span> <span class="n">TrainingConfig</span><span class="o">.</span><span class="n">get_optimizer_class_and_params</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">criterion_class</span><span class="p">,</span> <span class="n">criterion_class_params</span> <span class="o">=</span> <span class="n">TrainingConfig</span><span class="o">.</span><span class="n">get_criterion_class_and_params</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="c1"># Append the input_shape, output_shape, and additional_model_params to model_params</span>
        <span class="n">model_class_params</span><span class="p">[</span><span class="s1">&#39;input_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_shape</span>
        <span class="n">model_class_params</span><span class="p">[</span><span class="s1">&#39;output_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_shape</span>
        <span class="n">model_class_params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">additional_model_params</span><span class="p">)</span>

        <span class="c1"># Import Trainer Class</span>
        <span class="n">trainer_class</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">import_class_from_module</span><span class="p">(</span><span class="n">training_config_tuple_dict</span><span class="p">[</span><span class="s1">&#39;trainer_class_module_name&#39;</span><span class="p">],</span> <span class="n">training_config_tuple_dict</span><span class="p">[</span><span class="s1">&#39;trainer_class_name&#39;</span><span class="p">])</span>
        
        <span class="n">trainer_class_params</span> <span class="o">=</span> <span class="n">training_config_tuple_dict</span><span class="p">[</span><span class="s1">&#39;trainer_class_params&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">trainer_class</span><span class="p">(</span>
            <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span> 
            <span class="n">validation_dataloader</span><span class="o">=</span><span class="n">validation_dataloader</span><span class="p">,</span> 
            <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> 
            <span class="n">model_class</span><span class="o">=</span><span class="n">model_class</span><span class="p">,</span> 
            <span class="n">model_class_params</span><span class="o">=</span><span class="n">model_class_params</span><span class="p">,</span> 
            <span class="n">optimizer_class</span><span class="o">=</span><span class="n">optimizer_class</span><span class="p">,</span> 
            <span class="n">optimizer_class_params</span><span class="o">=</span><span class="n">optimizer_class_params</span><span class="p">,</span> 
            <span class="n">criterion_class</span><span class="o">=</span><span class="n">criterion_class</span><span class="p">,</span> 
            <span class="n">criterion_class_params</span><span class="o">=</span><span class="n">criterion_class_params</span><span class="p">,</span> 
            <span class="n">model_save_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_save_dir</span> <span class="o">+</span> <span class="p">(</span><span class="n">ModelConfig</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">TrainingTask</span> <span class="o">&amp;</span> <span class="n">key</span><span class="p">))</span><span class="o">.</span><span class="n">fetch1</span><span class="p">(</span><span class="s1">&#39;model_class_name&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">key</span><span class="p">[</span><span class="s1">&#39;training_task_md5_hash&#39;</span><span class="p">]</span>  <span class="o">+</span> <span class="s1">&#39;.pth&#39;</span><span class="p">,</span> 
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">training_config_tuple_dict</span><span class="p">[</span><span class="s1">&#39;epoch_limit&#39;</span><span class="p">],</span> 
            <span class="o">**</span><span class="n">trainer_class_params</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainingResult.plot_training_epoch_loss_history"><a class="viewcode-back" href="../../../synicix_ml_pipeline.datajoint_tables.html#synicix_ml_pipeline.datajoint_tables.TrainingResult.TrainingResult.plot_training_epoch_loss_history">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">plot_training_epoch_loss_history</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility analysis function that generate a plot of the training, validation, and test curves.</span>
<span class="sd">        By default it sets the title to &quot;&lt;model_class_name&gt;/&lt;training_task_md5_hash&gt;&quot;</span>

<span class="sd">        Parameters:</span>
<span class="sd">            key (dict): Dict to restrict TrainingResult.key_source by which is TrainingTask</span>
<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the TrainingTask and ModelConfig relationship</span>
        <span class="n">training_task_rel</span> <span class="o">=</span> <span class="n">TrainingTask</span> <span class="o">&amp;</span> <span class="n">key</span>
        <span class="n">model_config_rel</span> <span class="o">=</span> <span class="n">ModelConfig</span> <span class="o">&amp;</span> <span class="n">training_task_rel</span>

        <span class="c1"># Get the training_epoch_loss_history validation_epoch_loss_history and test_score</span>
        <span class="n">training_epoch_loss_history</span><span class="p">,</span> <span class="n">validation_epoch_loss_history</span><span class="p">,</span> <span class="n">test_score</span> <span class="o">=</span> <span class="p">(</span><span class="bp">cls</span> <span class="o">&amp;</span> <span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">fetch1</span><span class="p">(</span><span class="s1">&#39;training_epoch_loss_history&#39;</span><span class="p">,</span> <span class="s1">&#39;validation_epoch_loss_history&#39;</span><span class="p">,</span> <span class="s1">&#39;test_score&#39;</span><span class="p">)</span>

        <span class="c1"># Get the training_strip_length for interpelating the validation_poch_loss_history array for plotting</span>
        <span class="n">training_strip_length</span> <span class="o">=</span> <span class="p">(</span><span class="n">TrainingConfig</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">TrainingTask</span> <span class="o">&amp;</span> <span class="n">key</span><span class="p">))</span><span class="o">.</span><span class="n">fetch1</span><span class="p">(</span><span class="s1">&#39;training_strip_length&#39;</span><span class="p">)</span>

        <span class="c1"># Find the index and the value of the minumum validation score which is what used to compute the final score on the test set</span>
        <span class="n">min_validation_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">validation_epoch_loss_history</span> <span class="o">==</span> <span class="nb">min</span><span class="p">(</span><span class="n">validation_epoch_loss_history</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">min_validation_score_epoch</span> <span class="o">=</span> <span class="n">min_validation_index</span> <span class="o">*</span> <span class="n">training_strip_length</span>

        <span class="c1"># If the epoch for the min validation score is 0, it will technically be offset by 1 since 0th epoch means nothing is trained yet</span>
        <span class="k">if</span> <span class="n">min_validation_score_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">min_validation_score_epoch</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Create the dataframefor the  min_validation_df which will be use to plot the dot to represent it</span>
        <span class="n">min_validation_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="p">[</span><span class="n">min_validation_score_epoch</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="n">validation_epoch_loss_history</span><span class="p">[</span><span class="n">min_validation_index</span><span class="p">]],</span> <span class="n">loss_type</span><span class="o">=</span><span class="s1">&#39;min_validation&#39;</span><span class="p">))</span>

        <span class="c1">#  Compute the validation_epoch_loss_history_interp</span>
        <span class="n">training_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">training_epoch_loss_history</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">validation_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_epoch_loss_history</span><span class="p">)</span> <span class="o">*</span> <span class="n">training_strip_length</span><span class="p">,</span> <span class="n">training_strip_length</span><span class="p">)</span>
        <span class="n">validation_epochs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">validation_epoch_loss_history_interp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">,</span> <span class="n">validation_epochs</span><span class="p">,</span> <span class="n">validation_epoch_loss_history</span><span class="p">)</span>

        <span class="c1"># Test score</span>
        <span class="n">test_score_epoch_loss_history_interp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">,</span> <span class="p">[</span><span class="n">min_validation_score_epoch</span><span class="p">],</span> <span class="p">[</span><span class="n">test_score</span><span class="p">])</span>

        <span class="c1"># Plot MSE Baseline Loss Curve</span>
        <span class="n">training_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">training_epochs</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">training_epoch_loss_history</span><span class="p">,</span> <span class="n">loss_type</span> <span class="o">=</span> <span class="s1">&#39;training_epoch_loss_history&#39;</span><span class="p">))</span>
        <span class="n">validation_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">training_epochs</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">validation_epoch_loss_history_interp</span><span class="p">,</span> <span class="n">loss_type</span> <span class="o">=</span> <span class="s1">&#39;validation_epoch_loss_history&#39;</span><span class="p">))</span>
        <span class="n">test_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">training_epochs</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">test_score_epoch_loss_history_interp</span><span class="p">,</span> <span class="n">loss_type</span> <span class="o">=</span> <span class="s1">&#39;test_epoch_loss_history&#39;</span><span class="p">))</span>
        <span class="n">data_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">training_dataframe</span><span class="p">,</span> <span class="n">validation_dataframe</span><span class="p">,</span> <span class="n">test_dataframe</span><span class="p">])</span>
 
        <span class="c1"># Plot using seaborn</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_frame</span><span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">min_validation_df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">model_config_rel</span><span class="o">.</span><span class="n">fetch1</span><span class="p">(</span><span class="s1">&#39;model_class_name&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; / &#39;</span> <span class="o">+</span> <span class="n">training_task_rel</span><span class="o">.</span><span class="n">fetch1</span><span class="p">(</span><span class="s1">&#39;training_task_md5_hash&#39;</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Test Loss&#39;</span><span class="p">])</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Synicix

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>